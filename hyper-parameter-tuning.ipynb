{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:43:01.684170Z",
     "start_time": "2019-08-10T21:43:01.670915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check of your system and your brain :)\n",
    "\"A\" == \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:43:02.006985Z",
     "start_time": "2019-08-10T21:43:01.766201Z"
    }
   },
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "random_seed=42\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T21:14:49.104379Z",
     "start_time": "2019-05-05T21:14:48.015227Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Preparing data and black (In Orange framework, it is simple and good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:43:06.732193Z",
     "start_time": "2019-08-10T21:43:04.094646Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucy/Desktop/workspace/Descriptive-Induction-ML/prepare_dataset.py:153: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if '?' in df[col].unique():\n",
      "/Users/lucy/Desktop/workspace/Descriptive-Induction-ML/prepare_dataset.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col][df[col] == '?'] = df[col].value_counts().index[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train set (43957, 12)\n",
      "shape of test set (4885, 12)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "from prepare_dataset import prepare_adult_dataset,prepare_german_dataset,prepare_compas_dataset,prepare_pima_dataset,train_test_split_data,prepare_2d_sinusoidal_dataset\n",
    "from utils import encoder_from_datatable\n",
    "\n",
    "\n",
    "data_table,test_data_table = prepare_adult_dataset()\n",
    "# data_table,test_data_table = prepare_2d_sinusoidal_dataset()\n",
    "\n",
    "# data_table,test_data_table = prepare_german_dataset()\n",
    "\n",
    "# data_table,test_data_table = prepare_compas_dataset()\n",
    "\n",
    "# data_table, vali_data_table = train_test_split_data(data_table)\n",
    "# data_table,test_data_table = prepare_pima_dataset()\n",
    "\n",
    "print(\"shape of train set\", data_table.X.shape)\n",
    "# print(\"instances of evaluation set\", vali_data_table.X.shape[0])\n",
    "print(\"shape of test set\", test_data_table.X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:06.142581Z",
     "start_time": "2019-08-10T21:43:09.674830Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now start sanity-check\n",
      "the first row of the dataset is (orginal form):\n",
      " [20, Private, Some-college, Never-married, Other-service, Own-child, White, Female, 0, 0, 32, United-States | <=50K]\n",
      "the predition of blackbox on the first row:\n",
      " [0.]\n",
      "train set data set size, (43957, 12)\n",
      "test setdata set size, (4885, 12)\n",
      "data set size, [[20, Private, Some-college, Never-married, Other-service, Own-child, White, Female, 0, 0, 32, United-States | <=50K],\n",
      " [47, Private, Bachelors, Never-married, Sales, Own-child, White, Male, 0, 0, 40, United-States | <=50K],\n",
      " [35, Local-gov, HS-grad, Never-married, Adm-clerical, Unmarried, Amer-Indian-Eskimo, Male, 0, 0, 55, United-States | <=50K],\n",
      " [30, Private, Bachelors, Never-married, Sales, Own-child, White, Male, 0, 0, 40, United-States | >50K],\n",
      " [31, Self-emp-not-inc, Assoc-acdm, Married-civ-spouse, Other-service, Wife, White, Female, 0, 0, 35, United-States | >50K]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from prepare_blackbox import train_classifier\n",
    "\n",
    "black_box_model = train_classifier(data_table,classifier_method='dnn',random_seed=random_seed)\n",
    "# black_box_model = train_classifier(data_table,classifier_method='rf',random_seed=random_seed)\n",
    "\n",
    "\n",
    "\n",
    "black_box = lambda x: black_box_model.predict(x)\n",
    "# black_box = lambda x:  c.predict(scikit_encoder.transform(x))\n",
    "\n",
    "print(\"now start sanity-check\")\n",
    "print(\"the first row of the dataset is (orginal form):\\n\", data_table[0] )\n",
    "print(\"the predition of blackbox on the first row:\\n\", black_box( [data_table.X[0]]  )   )\n",
    "\n",
    "print(\"train set data set size,\",data_table.X.shape)\n",
    "print(\"test setdata set size,\",test_data_table.X.shape)\n",
    "print(\"data set size,\",data_table[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A sanity check of train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:09.996366Z",
     "start_time": "2019-08-10T21:45:06.147988Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc 0.9280660645630957\n",
      "Test acc 0.8354145342886387\n",
      "acc on training set 0.9280660645630957\n",
      "f1 on training set 0.8416149068322982\n",
      "recall on training set 0.7989538754160723\n",
      "precision on training set 0.8890887924648111\n",
      "acc on test set 0.8354145342886387\n",
      "f1 on test set 0.6375112714156899\n",
      "recall on test set 0.6032423208191127\n",
      "precision on test set 0.6759082217973231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "import sklearn\n",
    "# predict_fn = lambda x: aml.predict(H2OFrame(x)).as_data_frame().iloc[:,0].to_numpy()\n",
    "\n",
    "predict_fn = black_box\n",
    "\n",
    "print('Train acc', accuracy_score(data_table.Y, predict_fn(data_table.X)))\n",
    "print('Test acc', accuracy_score(test_data_table.Y, predict_fn(test_data_table.X)))\n",
    "\n",
    "print('acc on training set', sklearn.metrics.accuracy_score(data_table.Y, predict_fn(data_table.X)))\n",
    "print('f1 on training set', sklearn.metrics.f1_score(data_table.Y, predict_fn(data_table.X)))\n",
    "print('recall on training set', sklearn.metrics.recall_score(data_table.Y, predict_fn(data_table.X)))\n",
    "print('precision on training set', sklearn.metrics.precision_score(data_table.Y, predict_fn(data_table.X)))\n",
    "\n",
    "print('acc on test set', sklearn.metrics.accuracy_score(test_data_table.Y, predict_fn(test_data_table.X)))\n",
    "print('f1 on test set', sklearn.metrics.f1_score(test_data_table.Y, predict_fn(test_data_table.X)))\n",
    "print('recall on test set', sklearn.metrics.recall_score(test_data_table.Y, predict_fn(test_data_table.X)))\n",
    "print('precision on test set', sklearn.metrics.precision_score(test_data_table.Y, predict_fn(test_data_table.X)))\n",
    "\n",
    "\n",
    "# print('test f1', f1_score(y_test, predict_fn(X_test)))\n",
    "# print('test recall',recall_score(y_test, predict_fn(X_test)))\n",
    "# print('test precision', precision_score(y_test, predict_fn(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:11.291724Z",
     "start_time": "2019-08-10T21:45:10.006814Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, Private, Some-college, Never-married, Other-service, Own-child, White, Female, 0, 0, 32, United-States | <=50K],\n",
      " [47, Private, Bachelors, Never-married, Sales, Own-child, White, Male, 0, 0, 40, United-States | <=50K],\n",
      " [35, Local-gov, HS-grad, Never-married, Adm-clerical, Unmarried, Amer-Indian-Eskimo, Male, 0, 0, 55, United-States | <=50K],\n",
      " [30, Private, Bachelors, Never-married, Sales, Own-child, White, Male, 0, 0, 40, United-States | <=50K],\n",
      " [31, Self-emp-not-inc, Assoc-acdm, Married-civ-spouse, Other-service, Wife, White, Female, 0, 0, 35, United-States | >50K]]\n",
      "[[20.  3. 15.  4.  7.  3.  4.  0.  0.  0. 32. 38.]\n",
      " [47.  3.  9.  4. 11.  3.  4.  1.  0.  0. 40. 38.]\n",
      " [35.  1. 11.  4.  0.  4.  0.  1.  0.  0. 55. 38.]\n",
      " [30.  3.  9.  4. 11.  3.  4.  1.  0.  0. 40. 38.]\n",
      " [31.  5.  7.  2.  7.  5.  4.  0.  0.  0. 35. 38.]]\n",
      "43957\n",
      "4885\n",
      "sanity check, of acc,should be 100 1.0\n"
     ]
    }
   ],
   "source": [
    "black_box = predict_fn\n",
    "\n",
    "from utils import label_with_blackbox\n",
    "\n",
    "predicted_data_table = label_with_blackbox(data_table,black_box)\n",
    "\n",
    "predicted_test_data_table = label_with_blackbox(test_data_table,black_box)\n",
    "\n",
    "\n",
    "print(predicted_data_table[:5])\n",
    "print(predicted_data_table.X[:5])\n",
    "print(predicted_data_table.X.shape[0])\n",
    "print(predicted_test_data_table.X.shape[0])\n",
    "\n",
    "print('sanity check, of acc,should be 100', accuracy_score(predicted_data_table.Y, predict_fn(predicted_data_table.X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run once. Our approach Non-active mode ($\\beta=zero$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T06:58:31.425089Z",
     "start_time": "2019-08-11T06:52:15.155308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "init transformer okay!\n",
      "new cached!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0ea7de59584cf89233992b4bebbac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-54fb5cf882d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# l_parameter = 0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mexplanations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mADS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_data_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblack_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_parameter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml_parameter\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/approach.py\u001b[0m in \u001b[0;36mexplain_tabular\u001b[0;34m(dataset, blackbox, target_class_idx, pre_label, random_seed, beta, lambda_parameter, use_pre_mined, objective)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# quit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mrule_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;31m# print(\"the result accuracy\",explainer.compute_accuracy(rule_set))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# print(\"the number of rules\",len(rule_set))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/model.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_the_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_parameter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;31m# self.finish()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_representation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/model.py\u001b[0m in \u001b[0;36moutput_the_best\u001b[0;34m(self, lambda_parameter)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_the_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_parameter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlambda_parameter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_parameter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_solution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolution_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_class_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_class_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best solution found in iteration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from approach import explain_tabular\n",
    "l_parameter = 0.0001\n",
    "# l_parameter = 0.0005\n",
    "explanations,ADS = explain_tabular(predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed,beta=0,lambda_parameter=l_parameter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T00:45:19.982036Z",
     "start_time": "2019-08-11T00:45:19.896493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF 12614.0 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF 1894.5 <= capital-loss <= 1978.5 THEN income=>50K \n",
      "IF 5178.0 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF 7280.0 <= capital-gain <= 9999.900000000001 THEN income=>50K \n",
      "IF education is Bachelors,Doctorate AND marital-status is Married-civ-spouse AND occupation is Adm-clerical,Craft-repair,Prof-specialty,Sales,Tech-support,Transport-moving THEN income=>50K \n",
      "IF education is Doctorate THEN income=>50K \n",
      "IF education is Masters AND marital-status is Married-civ-spouse THEN income=>50K \n",
      "IF education is Masters AND native-country is Italy THEN income=>50K \n",
      "IF education is Prof-school AND marital-status is Married-civ-spouse THEN income=>50K \n",
      "IF native-country is Greece THEN income=>50K \n",
      "IF native-country is Taiwan THEN income=>50K \n",
      "IF native-country is Yugoslavia THEN income=>50K \n",
      "IF relationship is Other-relative AND 4999.950000000001 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF workclass is Federal-gov,Private AND occupation is Exec-managerial AND relationship is Husband THEN income=>50K \n",
      "886\n",
      "Blackbox and our, f1 score 0.7039337474120082\n",
      "Blackbox and our, acc 0.882906857727738\n",
      "Blackbox and our,recall 0.6500956022944551\n",
      "Blackbox and our,precision 0.7674943566591422\n",
      "number of rules: 14\n",
      "new instances 0\n",
      "number of rules 14\n",
      "ave number of conditions 1.5714285714285714\n",
      "max number of conditions 3\n",
      "used features 8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "# ADS.finish()\n",
    "# explanations = ADS.output_the_best(0.0003)\n",
    "for e in explanations:\n",
    "    print(rule_to_string(e,data_table.domain,target_class_idx=1))\n",
    "    \n",
    "our_prediction = ruleset_predict(explanations,test_data_table.X)\n",
    "\n",
    "print(sum(our_prediction) )\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from utils import  rule_to_string\n",
    "print('number of rules:',len(explanations))\n",
    "print(\"new instances\",ADS.synthetic_data_table.X.shape[0])\n",
    "\n",
    "from utils import compute_metrics\n",
    "\n",
    "compute_metrics(explanations,data_table.domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T00:45:28.429756Z",
     "start_time": "2019-08-11T00:45:19.996199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best solution found in iteration 644\n",
      "parameter:  0 0 metrics 16 0.7322953289804119 0.8908904810644831 0.6969407265774379 0.7714285714285715 0\n",
      "best solution found in iteration 644\n",
      "parameter:  0 1e-07 metrics 16 0.7322953289804119 0.8908904810644831 0.6969407265774379 0.7714285714285715 0\n",
      "best solution found in iteration 644\n",
      "parameter:  0 1e-06 metrics 16 0.7322953289804119 0.8908904810644831 0.6969407265774379 0.7714285714285715 0\n",
      "best solution found in iteration 644\n",
      "parameter:  0 1e-05 metrics 16 0.7322953289804119 0.8908904810644831 0.6969407265774379 0.7714285714285715 0\n",
      "best solution found in iteration 644\n",
      "parameter:  0 3e-05 metrics 16 0.7322953289804119 0.8908904810644831 0.6969407265774379 0.7714285714285715 0\n",
      "best solution found in iteration 644\n",
      "parameter:  0 5e-05 metrics 16 0.7322953289804119 0.8908904810644831 0.6969407265774379 0.7714285714285715 0\n",
      "best solution found in iteration 666\n",
      "parameter:  0 8e-05 metrics 14 0.7039337474120082 0.882906857727738 0.6500956022944551 0.7674943566591422 0\n",
      "best solution found in iteration 666\n",
      "parameter:  0 0.0001 metrics 14 0.7039337474120082 0.882906857727738 0.6500956022944551 0.7674943566591422 0\n",
      "best solution found in iteration 279\n",
      "parameter:  0 0.0005 metrics 9 0.7193432529502309 0.8880245649948822 0.6701720841300192 0.7763012181616833 0\n",
      "best solution found in iteration 292\n",
      "parameter:  0 0.001 metrics 8 0.7035657264502396 0.8859774820880245 0.6319311663479924 0.7935174069627852 0\n",
      "best solution found in iteration 292\n",
      "parameter:  0 0.0013 metrics 8 0.7035657264502396 0.8859774820880245 0.6319311663479924 0.7935174069627852 0\n",
      "best solution found in iteration 292\n",
      "parameter:  0 0.0015 metrics 8 0.7035657264502396 0.8859774820880245 0.6319311663479924 0.7935174069627852 0\n",
      "best solution found in iteration 294\n",
      "parameter:  0 0.0018 metrics 7 0.6926406926406927 0.883725690890481 0.6118546845124283 0.7980049875311721 0\n",
      "best solution found in iteration 294\n",
      "parameter:  0 0.002 metrics 7 0.6926406926406927 0.883725690890481 0.6118546845124283 0.7980049875311721 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.003 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.004 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.0045 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.005 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.006 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.007 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.008 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.01 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.015 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 163\n",
      "parameter:  0 0.02 metrics 3 0.6999500748876686 0.8769703172978506 0.6701720841300192 0.7324973876698014 0\n",
      "best solution found in iteration 3\n",
      "parameter:  0 0.03 metrics 1 0.37241379310344824 0.832343909928352 0.2323135755258126 0.9382239382239382 0\n",
      "best solution found in iteration 903\n",
      "parameter:  0 0.05 metrics 0 0.0 0.7858751279426817 0.0 0.0 0\n",
      "best solution found in iteration 903\n",
      "parameter:  0 0.1 metrics 0 0.0 0.7858751279426817 0.0 0.0 0\n",
      "best solution found in iteration 903\n",
      "parameter:  0 0.15 metrics 0 0.0 0.7858751279426817 0.0 0.0 0\n",
      "best solution found in iteration 903\n",
      "parameter:  0 0.2 metrics 0 0.0 0.7858751279426817 0.0 0.0 0\n",
      "best solution found in iteration 903\n",
      "parameter:  0 0.5 metrics 0 0.0 0.7858751279426817 0.0 0.0 0\n"
     ]
    }
   ],
   "source": [
    "lambda_candidates = [  0,0.0000001,0.000001,0.00001,0.00003,0.00005,0.00008,0.0001,0.0005,0.001,0.0013,0.0015,0.0018,0.002,0.003,0.004,0.0045,0.005,0.006,0.007,0.008,0.01,0.015,0.02,0.03,0.05,0.1,0.15,0.2,0.5 ]\n",
    "\n",
    "beta = 0\n",
    "for lambda_parameter in  lambda_candidates:\n",
    "    explanations = ADS.output_the_best(lambda_parameter)\n",
    "    our_prediction = ruleset_predict(explanations,test_data_table.X)\n",
    "    f1_score = sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction)\n",
    "    acc_score=sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction)\n",
    "    rec_score = sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction)\n",
    "    pre_score = sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction)\n",
    "    num = len(explanations)\n",
    "    num_of_instance = ADS.synthetic_data_table.X.shape[0]\n",
    "\n",
    "    print(\"parameter: \",beta,lambda_parameter,\"metrics\",num,f1_score,acc_score,rec_score,pre_score,num_of_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run once. Our approach active mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T01:01:28.101707Z",
     "start_time": "2019-08-11T00:45:28.437222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "init transformer okay!\n",
      "new cached!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb7a870689941d8926af183093ba2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best solution found in iteration 601\n",
      "Now print Error Log\n",
      "at iteration: 4 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 5 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 6 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 7 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 33 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 42 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 52 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 53 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 56 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 64 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 67 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 89 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 92 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 124 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 126 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 128 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 874 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 909 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 924 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 925 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 938 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 959 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 961 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 962 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 981 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from approach import explain_tabular\n",
    "# beta = 1.2e-04\n",
    "beta = 5e-05\n",
    "# beta = 1.5e-04\n",
    "l_parameter = 0.0001\n",
    "\n",
    "explanations_active,ADS_active = explain_tabular(predicted_data_table, black_box, target_class_idx=1, random_seed=42,beta=beta,lambda_parameter=l_parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T01:01:28.368539Z",
     "start_time": "2019-08-11T01:01:28.106083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rules 10\n",
      "IF 19999.800000000003 <= capital-gain <= 99999.0 AND 15.700000000000003 <= hours-per-week <= 99.0 THEN income=>50K \n",
      "IF 27.950000000000003 <= age <= 90.0 AND 9999.900000000001 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF 38.900000000000006 <= age <= 53.5 AND workclass is Federal-gov,Local-gov,Self-emp-inc AND education is Assoc-acdm,Assoc-voc,Some-college AND marital-status is Married-civ-spouse THEN income=>50K \n",
      "IF 7280.0 <= capital-gain <= 12614.0 AND native-country is Philippines,United-States THEN income=>50K \n",
      "IF education is Bachelors,Doctorate AND relationship is Husband,Wife AND 35.300000000000004 <= hours-per-week <= 74.5 THEN income=>50K \n",
      "IF education is Masters,Prof-school AND marital-status is Married-civ-spouse AND native-country is United-States THEN income=>50K \n",
      "IF education is Prof-school AND 50.5 <= hours-per-week <= 99.0 THEN income=>50K \n",
      "IF marital-status is Married-civ-spouse AND 1742.4 <= capital-loss <= 4356.0 THEN income=>50K \n",
      "IF marital-status is Married-civ-spouse AND 5094.697373187532 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF workclass is Federal-gov,Private AND occupation is Exec-managerial AND relationship is Husband,Wife THEN income=>50K \n",
      "925\n",
      "1046.0\n",
      "number of rules 10\n",
      "Blackbox and our, f1 score 0.732623033992897\n",
      "Blackbox and our, acc 0.8921187308085977\n",
      "Blackbox and our,recall 0.6902485659655831\n",
      "Blackbox and our,precision 0.7805405405405406\n",
      "number of rules 10\n",
      "ave number of conditions 2.5\n",
      "max number of conditions 4\n",
      "used features 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "# explanations_active = ADS_active.output_the_best(0.0001)\n",
    "print(\"num of rules\",len(explanations_active))\n",
    "for e in explanations_active:\n",
    "    print(rule_to_string(e,data_table.domain,target_class_idx=1))\n",
    "    \n",
    "our_prediction = ruleset_predict(explanations_active,test_data_table.X)\n",
    "\n",
    "print(sum(our_prediction) )\n",
    "\n",
    "from utils import label_with_blackbox\n",
    "predicted_test_data_table = label_with_blackbox(test_data_table,black_box)\n",
    "print(sum(predicted_test_data_table.Y) )\n",
    "print(\"number of rules\",len(explanations_active))\n",
    "import sklearn\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from utils import compute_metrics\n",
    "\n",
    "compute_metrics(explanations_active,data_table.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T01:01:40.354765Z",
     "start_time": "2019-08-11T01:01:28.371966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best solution found in iteration 586\n",
      "parameter:  5e-05 0 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 586\n",
      "parameter:  5e-05 1e-07 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 586\n",
      "parameter:  5e-05 1e-06 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 586\n",
      "parameter:  5e-05 1e-05 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 586\n",
      "parameter:  5e-05 3e-05 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 586\n",
      "parameter:  5e-05 5e-05 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 586\n",
      "parameter:  5e-05 8e-05 metrics 11 0.7313357034027427 0.8917093142272262 0.6883365200764818 0.7800650054171181 14766\n",
      "best solution found in iteration 601\n",
      "parameter:  5e-05 0.0001 metrics 10 0.732623033992897 0.8921187308085977 0.6902485659655831 0.7805405405405406 14766\n",
      "best solution found in iteration 601\n",
      "parameter:  5e-05 0.0005 metrics 10 0.732623033992897 0.8921187308085977 0.6902485659655831 0.7805405405405406 14766\n",
      "best solution found in iteration 602\n",
      "parameter:  5e-05 0.001 metrics 9 0.7311608961303463 0.891914022517912 0.6864244741873805 0.7821350762527233 14766\n",
      "best solution found in iteration 602\n",
      "parameter:  5e-05 0.0013 metrics 9 0.7311608961303463 0.891914022517912 0.6864244741873805 0.7821350762527233 14766\n",
      "best solution found in iteration 634\n",
      "parameter:  5e-05 0.0015 metrics 7 0.7217888715548622 0.8904810644831116 0.6634799235181644 0.7913340935005702 14766\n",
      "best solution found in iteration 634\n",
      "parameter:  5e-05 0.0018 metrics 7 0.7217888715548622 0.8904810644831116 0.6634799235181644 0.7913340935005702 14766\n",
      "best solution found in iteration 634\n",
      "parameter:  5e-05 0.002 metrics 7 0.7217888715548622 0.8904810644831116 0.6634799235181644 0.7913340935005702 14766\n",
      "best solution found in iteration 634\n",
      "parameter:  5e-05 0.0025 metrics 7 0.7217888715548622 0.8904810644831116 0.6634799235181644 0.7913340935005702 14766\n",
      "best solution found in iteration 636\n",
      "parameter:  5e-05 0.003 metrics 6 0.702819956616052 0.8878198567041965 0.6195028680688337 0.8120300751879699 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.005 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.006 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.007 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.008 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.01 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.015 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.02 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 755\n",
      "parameter:  5e-05 0.03 metrics 2 0.6928034371643393 0.882906857727738 0.6166347992351816 0.7904411764705882 14766\n",
      "best solution found in iteration 900\n",
      "parameter:  5e-05 0.05 metrics 1 0.37241379310344824 0.832343909928352 0.2323135755258126 0.9382239382239382 14766\n",
      "best solution found in iteration 900\n",
      "parameter:  5e-05 0.1 metrics 1 0.37241379310344824 0.832343909928352 0.2323135755258126 0.9382239382239382 14766\n",
      "best solution found in iteration 900\n",
      "parameter:  5e-05 0.15 metrics 1 0.37241379310344824 0.832343909928352 0.2323135755258126 0.9382239382239382 14766\n",
      "best solution found in iteration 900\n",
      "parameter:  5e-05 0.2 metrics 1 0.37241379310344824 0.832343909928352 0.2323135755258126 0.9382239382239382 14766\n",
      "best solution found in iteration 900\n",
      "parameter:  5e-05 0.5 metrics 1 0.37241379310344824 0.832343909928352 0.2323135755258126 0.9382239382239382 14766\n"
     ]
    }
   ],
   "source": [
    "lambda_candidates = [  0,0.0000001,0.000001,0.00001,0.00003,0.00005,0.00008,0.0001,0.0005,0.001,0.0013,0.0015,0.0018,0.002,0.0025,0.003,0.005,0.006,0.007,0.008,0.01,0.015,0.02,0.03,0.05,0.1,0.15,0.2,0.5 ]\n",
    "\n",
    "\n",
    "for lambda_parameter in  lambda_candidates:\n",
    "    explanations = ADS_active.output_the_best(lambda_parameter)\n",
    "    our_prediction = ruleset_predict(explanations,test_data_table.X)\n",
    "    f1_score = sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction)\n",
    "    acc_score=sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction)\n",
    "    rec_score = sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction)\n",
    "    pre_score = sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction)\n",
    "    num = len(explanations)\n",
    "    num_of_instance = ADS_active.synthetic_data_table.X.shape[0]\n",
    "\n",
    "    print(\"parameter: \",beta,lambda_parameter,\"metrics\",num,f1_score,acc_score,rec_score,pre_score,num_of_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T01:38:23.679710Z",
     "start_time": "2019-08-11T01:04:45.914277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "init transformer okay!\n",
      "new cached!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2759bda1ed574103a59642e4dd12d015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best solution found in iteration 772\n",
      "Now print Error Log\n",
      "at iteration: 4 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 5 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 6 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 7 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 33 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 364 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 368 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 388 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 390 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 391 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 392 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 393 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 428 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 451 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 454 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 455 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 468 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 486 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 502 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 523 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 524 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 531 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 532 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 533 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 534 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 537 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 682 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 683 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 929 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "at iteration: 966 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'REMOVE_CONDITION')\n",
      "num of rules 8\n",
      "IF 17.0 <= age <= 90.0 AND marital-status is Married-civ-spouse AND occupation is Exec-managerial THEN income=>50K \n",
      "IF 35.25 <= age <= 90.0 AND 34999.65 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF 9999.900000000001 <= capital-gain <= 99999.0 AND 0.0 <= capital-loss <= 4356.0 AND 35.300000000000004 <= hours-per-week <= 99.0 THEN income=>50K \n",
      "IF education is Assoc-acdm,Some-college AND relationship is Not-in-family AND 12614.0 <= capital-gain <= 99999.0 THEN income=>50K \n",
      "IF education is Bachelors,Doctorate AND marital-status is Married-civ-spouse THEN income=>50K \n",
      "IF education is Masters AND marital-status is Married-civ-spouse THEN income=>50K \n",
      "IF gender is Female,Male AND 7298.0 <= capital-gain <= 99999.0 AND 0.0 <= capital-loss <= 1742.4 THEN income=>50K \n",
      "IF marital-status is Married-civ-spouse AND 1848.0 <= capital-loss <= 4138.200000000001 AND native-country is United-States THEN income=>50K \n",
      "956\n",
      "1046.0\n",
      "number of rules 8\n",
      "Blackbox and our, f1 score 0.7112887112887113\n",
      "Blackbox and our, acc 0.8816786079836233\n",
      "Blackbox and our,recall 0.6806883365200764\n",
      "Blackbox and our,precision 0.7447698744769874\n",
      "number of rules 8\n",
      "ave number of conditions 2.625\n",
      "max number of conditions 3\n",
      "used features 10\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 0 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 1e-07 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 1e-06 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 1e-05 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 3e-05 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 5e-05 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 8e-05 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 772\n",
      "parameter:  0.0001 0.0001 metrics 8 0.7112887112887113 0.8816786079836233 0.6806883365200764 0.7447698744769874 29416\n",
      "best solution found in iteration 775\n",
      "parameter:  0.0001 0.0005 metrics 7 0.6865509761388285 0.8816786079836233 0.6051625239005736 0.793233082706767 29416\n",
      "best solution found in iteration 775\n",
      "parameter:  0.0001 0.001 metrics 7 0.6865509761388285 0.8816786079836233 0.6051625239005736 0.793233082706767 29416\n",
      "best solution found in iteration 775\n",
      "parameter:  0.0001 0.0013 metrics 7 0.6865509761388285 0.8816786079836233 0.6051625239005736 0.793233082706767 29416\n",
      "best solution found in iteration 775\n",
      "parameter:  0.0001 0.0015 metrics 7 0.6865509761388285 0.8816786079836233 0.6051625239005736 0.793233082706767 29416\n",
      "best solution found in iteration 820\n",
      "parameter:  0.0001 0.0018 metrics 4 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.002 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.0025 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.003 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.005 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.006 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.007 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.008 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 822\n",
      "parameter:  0.0001 0.01 metrics 3 0.6866485013623979 0.8822927328556807 0.6022944550669216 0.7984790874524715 29416\n",
      "best solution found in iteration 895\n",
      "parameter:  0.0001 0.015 metrics 2 0.6694045174537987 0.8681678607983623 0.6233269598470363 0.7228381374722838 29416\n",
      "best solution found in iteration 895\n",
      "parameter:  0.0001 0.02 metrics 2 0.6694045174537987 0.8681678607983623 0.6233269598470363 0.7228381374722838 29416\n",
      "best solution found in iteration 426\n",
      "parameter:  0.0001 0.03 metrics 1 0.3493312352478364 0.8307062436028659 0.21223709369024857 0.9866666666666667 29416\n",
      "best solution found in iteration 426\n",
      "parameter:  0.0001 0.05 metrics 1 0.3493312352478364 0.8307062436028659 0.21223709369024857 0.9866666666666667 29416\n",
      "best solution found in iteration 426\n",
      "parameter:  0.0001 0.1 metrics 1 0.3493312352478364 0.8307062436028659 0.21223709369024857 0.9866666666666667 29416\n",
      "best solution found in iteration 426\n",
      "parameter:  0.0001 0.15 metrics 1 0.3493312352478364 0.8307062436028659 0.21223709369024857 0.9866666666666667 29416\n",
      "best solution found in iteration 426\n",
      "parameter:  0.0001 0.2 metrics 1 0.3493312352478364 0.8307062436028659 0.21223709369024857 0.9866666666666667 29416\n",
      "best solution found in iteration 37\n",
      "parameter:  0.0001 0.5 metrics 0 0.0 0.7858751279426817 0.0 0.0 29416\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from approach import explain_tabular\n",
    "# beta = 1.2e-04\n",
    "beta = 1e-4\n",
    "# beta = 1.5e-04\n",
    "l_parameter = 0.0001\n",
    "\n",
    "explanations_active,ADS_active = explain_tabular(predicted_data_table, black_box, target_class_idx=1, random_seed=42,beta=beta,lambda_parameter=l_parameter)\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "# explanations_active = ADS_active.output_the_best(0.0001)\n",
    "print(\"num of rules\",len(explanations_active))\n",
    "for e in explanations_active:\n",
    "    print(rule_to_string(e,data_table.domain,target_class_idx=1))\n",
    "    \n",
    "our_prediction = ruleset_predict(explanations_active,test_data_table.X)\n",
    "\n",
    "print(sum(our_prediction) )\n",
    "\n",
    "from utils import label_with_blackbox\n",
    "predicted_test_data_table = label_with_blackbox(test_data_table,black_box)\n",
    "print(sum(predicted_test_data_table.Y) )\n",
    "print(\"number of rules\",len(explanations_active))\n",
    "import sklearn\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from utils import compute_metrics\n",
    "\n",
    "compute_metrics(explanations_active,data_table.domain)\n",
    "\n",
    "lambda_candidates = [  0,0.0000001,0.000001,0.00001,0.00003,0.00005,0.00008,0.0001,0.0005,0.001,0.0013,0.0015,0.0018,0.002,0.0025,0.003,0.005,0.006,0.007,0.008,0.01,0.015,0.02,0.03,0.05,0.1,0.15,0.2,0.5 ]\n",
    "\n",
    "\n",
    "for lambda_parameter in  lambda_candidates:\n",
    "    explanations = ADS_active.output_the_best(lambda_parameter)\n",
    "    our_prediction = ruleset_predict(explanations,test_data_table.X)\n",
    "    f1_score = sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction)\n",
    "    acc_score=sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction)\n",
    "    rec_score = sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction)\n",
    "    pre_score = sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction)\n",
    "    num = len(explanations)\n",
    "    num_of_instance = ADS_active.synthetic_data_table.X.shape[0]\n",
    "\n",
    "    print(\"parameter: \",beta,lambda_parameter,\"metrics\",num,f1_score,acc_score,rec_score,pre_score,num_of_instance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T23:01:24.456172Z",
     "start_time": "2019-08-07T23:01:24.393434Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadad\n"
     ]
    }
   ],
   "source": [
    "print(\"loadad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T23:07:42.958313Z",
     "start_time": "2019-08-07T23:01:25.738327Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "start Apriori\n",
      "finish Apriori. Converting itemset\n",
      "Pre-mined okay. all pre-mined rules of 9742\n",
      "data set shape 43957\n",
      "init compute\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2312cef247f44a608699a5791f8f75a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9742), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c7c88d2b24ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcompetition_methods_explanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpassive_methods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplain_tabular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0miter_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mexplanations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_predicted_data_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblack_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# explanations = explain_tabular(data_table, black_box, target_class_idx=1, random_seed=random_seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/passive_methods/ids.py\u001b[0m in \u001b[0;36mexplain_tabular\u001b[0;34m(dataset, blackbox, target_class_idx, pre_label, random_seed)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# lambda_array = [1.0]*7     # use separate hyperparamter search routine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mlambda_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# use separate hyperparamter search routine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_local_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_rules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_local_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_rules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_rules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/passive_methods/IDS/IDS_smooth_local.py\u001b[0m in \u001b[0;36msmooth_local_search\u001b[0;34m(list_rules, df, Y, lambda_array, delta, delta_prime)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"init compute\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_rules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_correct_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/passive_methods/IDS/IDS_smooth_local.py\u001b[0m in \u001b[0;36mget_cover\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_bit_map_rule_get_cover\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_bit_map_rule_get_cover\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cover_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_bit_map_rule_get_cover\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/passive_methods/IDS/IDS_smooth_local.py\u001b[0m in \u001b[0;36mget_cover_\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# new = df.apply( lambda x: all([ x[pattern[0]] == pattern[1] for pattern in self.itemset ]),axis=1  )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mset_of_cover_per_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mget_cover_condition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mset_of_cover_per_condition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# print('\\tTook %0.3fs to get the cover' % (time.time() - start_time) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# print(list(dfnew.index.values))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import Orange\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "# disc.method = Orange.preprocess.discretize.EqualFreq(n=3)\n",
    "\n",
    "disc_predicted_data_table = disc(predicted_data_table)\n",
    "# disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "disc_predicted_test_data_table = Orange.data.Table.from_table(disc_predicted_data_table.domain, predicted_test_data_table)\n",
    "\n",
    "from competition_methods_explanation.passive_methods.ids import explain_tabular\n",
    "iter_max = 1000\n",
    "explanations = explain_tabular(disc_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed)\n",
    "# explanations = explain_tabular(data_table, black_box, target_class_idx=1, random_seed=random_seed)\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "our_prediction = ruleset_predict(explanations,disc_predicted_test_data_table.X)\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from competition_methods_explanation.passive_methods.ids import compute_metrics_ids\n",
    "compute_metrics_ids(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T23:07:42.961685Z",
     "start_time": "2019-08-07T23:01:26.050Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Orange\n",
    "\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "\n",
    "disc_predicted_data_table = disc(predicted_data_table)\n",
    "# disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "disc_predicted_test_data_table = Orange.data.Table.from_table(disc_predicted_data_table.domain, predicted_test_data_table)\n",
    "\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "\n",
    "rate = 1.0 * 49804 / predicted_data_table.X.shape[0] \n",
    "# rate = 1.13\n",
    "print(\"sampling rate\",rate)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "print(new_predicted_data_table.X.shape)\n",
    "disc_new_predicted_data_table =  Orange.data.Table.from_table(disc_predicted_data_table.domain, new_predicted_data_table)\n",
    "\n",
    "\n",
    "from competition_methods_explanation.passive_methods.ids import explain_tabular\n",
    "explanations = explain_tabular(disc_new_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed)\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "our_prediction = ruleset_predict(explanations,disc_predicted_test_data_table.X)\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from competition_methods_explanation.passive_methods.ids import compute_metrics_ids\n",
    "compute_metrics_ids(explanations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:24:17.557154Z",
     "start_time": "2019-08-08T10:24:17.507180Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any([[True, False], [False, False],[False, False]], axis=0)\n",
    "# print(\"dasdas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T11:18:48.065160Z",
     "start_time": "2019-08-08T10:24:17.560242Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "init transformer okay!\n",
      "new cached!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075e578ed42847d194bafa2b700dbeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pre-mined rules\n",
      "start Generating rule space.  Min support: 0.01\n",
      "number of premined rules 46902\n",
      "Screening rules using information gain\n",
      "\tTook 1957.627s to generate 2 rules\n",
      "\n",
      "best solution found in iteration 775\n",
      "Now print Error Log\n",
      "at iteration: 2 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 3 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 4 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 14 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 21 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 22 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 23 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 58 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 85 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 87 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 108 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 109 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 110 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 130 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 138 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 141 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 142 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 145 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 161 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 169 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 180 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 181 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 184 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 187 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 188 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 189 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 190 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 194 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 211 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 212 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 244 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 246 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 260 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 269 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 305 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 308 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 311 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 331 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 335 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 364 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 365 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 399 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 414 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 415 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 465 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 472 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 475 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 477 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 498 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 509 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 511 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 512 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 516 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 517 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 518 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 520 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 523 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 532 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 543 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 556 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 557 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 558 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 561 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 587 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 588 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 590 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 594 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 613 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 614 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 615 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 619 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 652 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 653 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 660 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 661 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 695 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 702 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 710 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 715 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 730 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 742 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 771 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 772 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 773 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 775 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 811 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 813 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 816 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 817 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 823 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 840 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 859 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 884 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 886 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 892 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 899 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 903 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 905 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 906 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'ADD_RULE')\n",
      "at iteration: 974 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n",
      "at iteration: 985 happens the following error\n",
      "('no plausible actions, len length of actions', 0, 'in the mode of ', 'SPECIFY_CONDITION')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import Orange\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "# disc.method = Orange.preprocess.discretize.EqualFreq(n=3)\n",
    "\n",
    "disc_predicted_data_table = disc(predicted_data_table)\n",
    "# disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "disc_predicted_test_data_table = Orange.data.Table.from_table(disc_predicted_data_table.domain, predicted_test_data_table)\n",
    "\n",
    "# from competition_methods_explanation.passive_methods.brs import explain_tabular\n",
    "from approach import explain_tabular\n",
    "explanations,explainer = explain_tabular(disc_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed,beta = 0,use_pre_mined=True, objective = 'bayesian')\n",
    "# explanations = explain_tabular(data_table, black_box, target_class_idx=1, random_seed=random_seed)\n",
    "# explanations,explainer = explain_tabular(disc_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed,beta = 0,use_pre_mined=True, objective = 'simple')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T11:18:48.451234Z",
     "start_time": "2019-08-08T11:18:48.070827Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF capital-gain is 3048 - 3120,4243.5 - 4401,5119 - 5316.5,≥ 7055.5 THEN income=>50K \n",
      "IF capital-gain is 4668.5 - 4826 THEN income=>50K \n",
      "IF capital-loss is 1551.5 - 1568.5,1881.5 - 1927.5,1975.5 - 1978.5 THEN income=>50K \n",
      "IF capital-loss is 2364.5 - 3089.5 AND native-country is Poland,United-States THEN income=>50K \n",
      "IF education is Assoc-acdm,Bachelors,Doctorate,Masters,Prof-school AND marital-status is Married-civ-spouse AND capital-gain is < 57 THEN income=>50K \n",
      "IF marital-status is Married-civ-spouse AND gender is Female,Male AND capital-gain is < 57 AND capital-loss is 1820.5 - 1859 THEN income=>50K \n",
      "IF relationship is Unmarried AND capital-gain is 4826 - 5119 AND capital-loss is < 1551.5 AND native-country is United-States THEN income=>50K \n",
      "8197\n",
      "Blackbox and our, acc 0.8928498305161863\n",
      "Blackbox and our, f1 score 0.7330839850391023\n",
      "Blackbox and our,recall 0.6845168800931315\n",
      "Blackbox and our,precision 0.7890691716481639\n",
      "number of rules 7\n",
      "ave number of conditions 2.2857142857142856\n",
      "max number of conditions 4\n",
      "used features 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "for e in explanations:\n",
    "    try:\n",
    "        print(rule_to_string(e,disc_predicted_data_table.domain,target_class_idx=1))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "        \n",
    "disc_predicted_test_data_table = disc_predicted_data_table\n",
    "our_prediction = ruleset_predict(explanations,disc_predicted_test_data_table.X)\n",
    "\n",
    "print( sum(our_prediction) )\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from competition_methods_explanation.passive_methods.brs import compute_metrics_brs\n",
    "compute_metrics_brs(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-08T19:01:30.857Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "sampling rate 1.1330163568942375\n",
      "(93761, 12)\n",
      "init transformer okay!\n",
      "new cached!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b20861c4fc3416688bf62f8248315c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pre-mined rules\n",
      "start Generating rule space.  Min support: 0.01\n",
      "number of premined rules 42385\n",
      "Screening rules using information gain\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Orange\n",
    "\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "# disc.method = Orange.preprocess.discretize.EqualFreq(n=3)\n",
    "\n",
    "disc_predicted_data_table = disc(predicted_data_table)\n",
    "# disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "disc_predicted_test_data_table = Orange.data.Table.from_table(disc_predicted_data_table.domain, predicted_test_data_table)\n",
    "\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "\n",
    "rate = 1.0 * 49804 / predicted_data_table.X.shape[0] \n",
    "print(\"sampling rate\",rate)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "print(new_predicted_data_table.X.shape)\n",
    "disc_new_predicted_data_table =  Orange.data.Table.from_table(disc_predicted_data_table.domain, new_predicted_data_table)\n",
    "\n",
    "from approach import explain_tabular\n",
    "explanations,explainer = explain_tabular(disc_new_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed,beta = 0,use_pre_mined=True, objective = 'bayesian')\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "our_prediction = ruleset_predict(explanations,disc_predicted_test_data_table.X)\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(disc_predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from competition_methods_explanation.passive_methods.brs import compute_metrics_brs\n",
    "compute_metrics_brs(explanations)\n",
    "\n",
    "# from competition_methods_explanation.passive_methods.brs import explain_tabular\n",
    "# explanations = explain_tabular(disc_new_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-08T19:01:31.187Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SBRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T23:18:47.773277Z",
     "start_time": "2019-08-05T22:50:06.703710Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "sampling rate 1.1330163568942375\n",
      "first discretize data since SBRL only handles categorical data\n",
      "initialize okay\n",
      "start finding rule list\n",
      "finished finding rule list\n",
      "metrics 143 0.76200101061142 0.903582395087001 0.7208413001912046 0.8081457663451233 49804.0\n",
      "number of rules 143\n",
      "ave number of conditions 1.8531468531468531\n",
      "max number of conditions 2\n",
      "used features 12\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Orange\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "\n",
    "disc_predicted_data_table = disc(predicted_data_table)\n",
    "# disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "disc_predicted_test_data_table = Orange.data.Table.from_table(disc_predicted_data_table.domain, predicted_test_data_table)\n",
    "\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "\n",
    "from competition_methods_explanation.passive_methods.brl import explain_tabular\n",
    "\n",
    "\n",
    "from utils import ruleset_predict\n",
    "from copy import deepcopy\n",
    "import sklearn\n",
    "sampling_rate_candidates = [0,0.5,1,1.5,2]\n",
    "\n",
    "rate = 1.0 * 49804 / predicted_data_table.X.shape[0] \n",
    "print(\"sampling rate\",rate)\n",
    "# new_predicted_data_table = uniform_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "        \n",
    "disc_new_predicted_data_table =  Orange.data.Table.from_table(disc_predicted_data_table.domain, new_predicted_data_table)\n",
    "\n",
    "sbrl = explain_tabular(disc_new_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed)\n",
    "\n",
    "sbrl_prediction = sbrl.predict( (disc_predicted_test_data_table.X).astype(int)  )\n",
    "\n",
    "f1_score = sklearn.metrics.f1_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "acc_score=sklearn.metrics.accuracy_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "rec_score = sklearn.metrics.recall_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "pre_score = sklearn.metrics.precision_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "num = sbrl.n_rules\n",
    "num_of_instance = rate * predicted_data_table.X.shape[0]\n",
    "\n",
    "print(\"metrics\",num,f1_score,acc_score,rec_score,pre_score,num_of_instance)\n",
    "\n",
    "from competition_methods_explanation.passive_methods.brl import compute_metrics_sbrl\n",
    "compute_metrics_sbrl(sbrl.rule_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T00:01:24.451908Z",
     "start_time": "2019-08-05T23:50:58.114429Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "sampling rate 0\n",
      "first discretize data since SBRL only handles categorical data\n",
      "initialize okay\n",
      "start finding rule list\n",
      "finished finding rule list\n",
      "metrics 94 0.7588582677165354 0.8996929375639714 0.737093690248566 0.781947261663286 0\n",
      "number of rules 94\n",
      "ave number of conditions 1.702127659574468\n",
      "max number of conditions 2\n",
      "used features 12\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Orange\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "\n",
    "disc = Orange.preprocess.Discretize()\n",
    "disc.method = Orange.preprocess.discretize.EntropyMDL()\n",
    "\n",
    "disc_predicted_data_table = disc(predicted_data_table)\n",
    "# disc_predicted_test_data_table = disc(predicted_test_data_table)\n",
    "disc_predicted_test_data_table = Orange.data.Table.from_table(disc_predicted_data_table.domain, predicted_test_data_table)\n",
    "\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "\n",
    "from competition_methods_explanation.passive_methods.brl import explain_tabular\n",
    "\n",
    "\n",
    "from utils import ruleset_predict\n",
    "from copy import deepcopy\n",
    "import sklearn\n",
    "\n",
    "sampling_rate_candidates = [0,0.5,1,1.5,2]\n",
    "\n",
    "rate = 0\n",
    "print(\"sampling rate\",rate)\n",
    "# new_predicted_data_table = uniform_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "        \n",
    "disc_new_predicted_data_table =  Orange.data.Table.from_table(disc_predicted_data_table.domain, new_predicted_data_table)\n",
    "\n",
    "sbrl = explain_tabular(disc_new_predicted_data_table, black_box, target_class_idx=1, random_seed=random_seed)\n",
    "\n",
    "sbrl_prediction = sbrl.predict( (disc_predicted_test_data_table.X).astype(int)  )\n",
    "\n",
    "f1_score = sklearn.metrics.f1_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "acc_score=sklearn.metrics.accuracy_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "rec_score = sklearn.metrics.recall_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "pre_score = sklearn.metrics.precision_score(predicted_test_data_table.Y, sbrl_prediction)\n",
    "num = sbrl.n_rules\n",
    "num_of_instance = rate * predicted_data_table.X.shape[0]\n",
    "\n",
    "\n",
    "print(\"metrics\",num,f1_score,acc_score,rec_score,pre_score,num_of_instance)\n",
    "from competition_methods_explanation.passive_methods.brl import compute_metrics_sbrl\n",
    "compute_metrics_sbrl(sbrl.rule_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.021766Z",
     "start_time": "2019-08-03T10:16:17.708Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:11.543644Z",
     "start_time": "2019-08-10T21:45:11.295383Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046.0\n",
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.7573604060913706\n",
      "Blackbox and our, acc 0.9021494370522006\n",
      "Blackbox and our,recall 0.7131931166347992\n",
      "Blackbox and our,precision 0.8073593073593074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "# c_passive = MLPClassifier(solver='adam', alpha=1e-5,  hidden_layer_sizes=(100, 100,50,50,10), random_state=random_seed,verbose=False)\n",
    "# c_passive =RandomForestClassifier(n_estimators=300, n_jobs=5)\n",
    "# c_passive= SVC(gamma='scale')\n",
    "# c_passive= DecisionTreeClassifier(max_depth=10)\n",
    "c_passive= DecisionTreeClassifier(random_state=random_seed,max_leaf_nodes=133)\n",
    "\n",
    "\n",
    "# from sklearn.compose import make_column_transformer\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder,Normalizer\n",
    "# categorical_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_discrete]\n",
    "# encoder = make_column_transformer( ( OneHotEncoder(categories='auto',sparse=False),categorical_features_idx),\n",
    "#                             remainder = 'passthrough'\n",
    "#                             )\n",
    "# encoder.fit(predicted_data_table.X)\n",
    "# c_passive.fit(encoder.transform(predicted_data_table.X), predicted_data_table.Y)\n",
    "# black_prediction = c_passive.predict(encoder.transform(predicted_test_data_table.X))\n",
    "\n",
    "c_passive.fit(predicted_data_table.X, predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict(predicted_test_data_table.X)\n",
    "\n",
    "print(sum(predicted_test_data_table.Y) )\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:11.719025Z",
     "start_time": "2019-08-10T21:45:11.548896Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leaves 133\n",
      "average number of conditions 6.548872180451128\n",
      "max number of conditions 10\n",
      "feature used 10\n"
     ]
    }
   ],
   "source": [
    "estimator = c_passive\n",
    "n_nodes = estimator.tree_.node_count\n",
    "children_left = estimator.tree_.children_left\n",
    "children_right = estimator.tree_.children_right\n",
    "feature = estimator.tree_.feature\n",
    "threshold = estimator.tree_.threshold\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "\n",
    "# from collections import defaultdict\n",
    "# defaultdict(list)\n",
    "parents = {}\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "        parents[ children_left[node_id]  ] = node_id\n",
    "        parents[ children_right[node_id]  ] = node_id\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "# print( len(parents) )\n",
    "        \n",
    "print(\"number of leaves\",sum(is_leaves) )\n",
    "\n",
    "leave_nodes = [ i for i in range( len(is_leaves) ) if is_leaves[i]==True ] \n",
    "\n",
    "paths_of_leave_nodes = {}\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i] == True:\n",
    "        path = []\n",
    "        tmp = i\n",
    "        while( tmp >=0 and tmp in parents) :\n",
    "            tmp_parent = parents[tmp]\n",
    "            path.append(tmp_parent)\n",
    "            tmp = tmp_parent\n",
    "            \n",
    "        paths_of_leave_nodes[i] = path\n",
    "\n",
    "print(\"average number of conditions\", sum ( [   len(set(  feature[n]  for n in paths_of_leave_nodes[i]     ))    for i in leave_nodes] ) / len(leave_nodes)  )\n",
    "print(\"max number of conditions\", max([   len(set(  feature[n]  for n in paths_of_leave_nodes[i]     ))    for i in leave_nodes] )  )\n",
    "\n",
    "features_used = set ( [feature[i] for i in range(n_nodes)  if is_leaves[i]!=True ]  ) # the feature array does not use any feature split\n",
    "print(\"feature used\", len(features_used))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T02:00:52.339977Z",
     "start_time": "2019-08-06T02:00:47.877716Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate 1.116636713151489\n",
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.7967939651107968\n",
      "Blackbox and our, acc 0.9117707267144319\n",
      "Blackbox and our,recall 0.8078393881453155\n",
      "Blackbox and our,precision 0.786046511627907\n",
      "number of leaves 7741\n",
      "average number of conditions 8.66464281100633\n",
      "max number of conditions 12\n",
      "feature used 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "c_passive= DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "rate = ADS_active.synthetic_data_table.X.shape[0] / predicted_data_table.X.shape[0]\n",
    "print(\"sampling rate\",rate)\n",
    "# new_predicted_data_table = uniform_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "\n",
    "\n",
    "c_passive.fit(new_predicted_data_table.X, new_predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict(predicted_test_data_table.X)\n",
    "\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "\n",
    "estimator = c_passive\n",
    "n_nodes = estimator.tree_.node_count\n",
    "children_left = estimator.tree_.children_left\n",
    "children_right = estimator.tree_.children_right\n",
    "feature = estimator.tree_.feature\n",
    "threshold = estimator.tree_.threshold\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "\n",
    "# from collections import defaultdict\n",
    "# defaultdict(list)\n",
    "parents = {}\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "        parents[ children_left[node_id]  ] = node_id\n",
    "        parents[ children_right[node_id]  ] = node_id\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "# print( len(parents) )\n",
    "        \n",
    "print(\"number of leaves\",sum(is_leaves) )\n",
    "\n",
    "leave_nodes = [ i for i in range( len(is_leaves) ) if is_leaves[i]==True ] \n",
    "\n",
    "paths_of_leave_nodes = {}\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i] == True:\n",
    "        path = []\n",
    "        tmp = i\n",
    "        while( tmp >=0 and tmp in parents) :\n",
    "            tmp_parent = parents[tmp]\n",
    "            path.append(tmp_parent)\n",
    "            tmp = tmp_parent\n",
    "            \n",
    "        paths_of_leave_nodes[i] = path\n",
    "\n",
    "print(\"average number of conditions\", sum ( [   len(set(  feature[n]  for n in paths_of_leave_nodes[i]     ))    for i in leave_nodes] ) / len(leave_nodes)  )\n",
    "print(\"max number of conditions\", max([   len(set(  feature[n]  for n in paths_of_leave_nodes[i]     ))    for i in leave_nodes] )  )\n",
    "\n",
    "features_used = set ( [feature[i] for i in range(n_nodes)  if is_leaves[i]!=True ]  ) # the feature array does not use any feature split\n",
    "print(\"feature used\", len(features_used))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T02:33:34.972176Z",
     "start_time": "2019-08-06T02:33:34.585086Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046.0\n",
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.8242485990830362\n",
      "Blackbox and our, acc 0.9293756397134084\n",
      "Blackbox and our,recall 0.7734225621414914\n",
      "Blackbox and our,precision 0.8822246455834242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "# c_passive = MLPClassifier(solver='adam', alpha=1e-5,  hidden_layer_sizes=(100, 100,50,50,10), random_state=random_seed,verbose=False)\n",
    "c_passive =RandomForestClassifier(random_state=random_seed)\n",
    "# c_passive= SVC(gamma='scale')\n",
    "# c_passive= DecisionTreeClassifier(max_depth=10)\n",
    "# c_passive= DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "\n",
    "# from sklearn.compose import make_column_transformer\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder,Normalizer\n",
    "# categorical_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_discrete]\n",
    "# encoder = make_column_transformer( ( OneHotEncoder(categories='auto',sparse=False),categorical_features_idx),\n",
    "#                             remainder = 'passthrough'\n",
    "#                             )\n",
    "# encoder.fit(predicted_data_table.X)\n",
    "# c_passive.fit(encoder.transform(predicted_data_table.X), predicted_data_table.Y)\n",
    "# black_prediction = c_passive.predict(encoder.transform(predicted_test_data_table.X))\n",
    "\n",
    "c_passive.fit(predicted_data_table.X, predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict(predicted_test_data_table.X)\n",
    "\n",
    "print(sum(predicted_test_data_table.Y) )\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T02:35:14.412769Z",
     "start_time": "2019-08-06T02:35:12.847149Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all leaves 44687\n",
      "average number of conditions 9.571351847293396\n",
      "max number of conditions 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_path_from_tree(decision_tree):\n",
    "    \n",
    "    \n",
    "\n",
    "    n_nodes = decision_tree.tree_.node_count\n",
    "    children_left = decision_tree.tree_.children_left\n",
    "    children_right = decision_tree.tree_.children_right\n",
    "    feature = decision_tree.tree_.feature\n",
    "    threshold = decision_tree.tree_.threshold\n",
    "\n",
    "    # The tree structure can be traversed to compute various properties such\n",
    "    # as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "\n",
    "    parents = {}\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "            parents[ children_left[node_id]  ] = node_id\n",
    "            parents[ children_right[node_id]  ] = node_id\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "\n",
    "    leave_nodes = [ i for i in range( len(is_leaves) ) if is_leaves[i]==True ] \n",
    "\n",
    "    paths_of_leave_nodes = {}\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i] == True:\n",
    "            path = []\n",
    "            tmp = i\n",
    "            while( tmp >=0 and tmp in parents) :\n",
    "                tmp_parent = parents[tmp]\n",
    "                path.append(tmp_parent)\n",
    "                tmp = tmp_parent\n",
    "\n",
    "            paths_of_leave_nodes[i] = path\n",
    "    return [   set(  feature[n]  for n in paths_of_leave_nodes[i]  ) for i in leave_nodes]\n",
    "\n",
    "list_of_paths = [ get_path_from_tree(t) for t in c_passive.estimators_ ]\n",
    "import itertools\n",
    "all_paths = list(itertools.chain.from_iterable(list_of_paths))\n",
    "\n",
    "\n",
    "print(\"number of all leaves\", len(all_paths))\n",
    "print(\"average number of conditions\", sum ( [   len(i)    for i in all_paths] ) / len(all_paths)  )\n",
    "print(\"max number of conditions\", max ( [   len(i)    for i in all_paths] ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T02:36:58.372511Z",
     "start_time": "2019-08-06T02:36:50.473420Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate 1.116636713151489\n",
      "1046.0\n",
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.8310362429811129\n",
      "Blackbox and our, acc 0.9322415557830092\n",
      "Blackbox and our,recall 0.7782026768642447\n",
      "Blackbox and our,precision 0.891566265060241\n",
      "number of all leaves 82850\n",
      "average number of conditions 9.32267954133977\n",
      "max number of conditions 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "\n",
    "c_passive =RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "rate = ADS_active.synthetic_data_table.X.shape[0] / predicted_data_table.X.shape[0]\n",
    "print(\"sampling rate\",rate)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "\n",
    "\n",
    "c_passive.fit(new_predicted_data_table.X, new_predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict(predicted_test_data_table.X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(sum(predicted_test_data_table.Y) )\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_path_from_tree(decision_tree):\n",
    "    \n",
    "    \n",
    "\n",
    "    n_nodes = decision_tree.tree_.node_count\n",
    "    children_left = decision_tree.tree_.children_left\n",
    "    children_right = decision_tree.tree_.children_right\n",
    "    feature = decision_tree.tree_.feature\n",
    "    threshold = decision_tree.tree_.threshold\n",
    "\n",
    "    # The tree structure can be traversed to compute various properties such\n",
    "    # as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "\n",
    "    parents = {}\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "            parents[ children_left[node_id]  ] = node_id\n",
    "            parents[ children_right[node_id]  ] = node_id\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "\n",
    "    leave_nodes = [ i for i in range( len(is_leaves) ) if is_leaves[i]==True ] \n",
    "\n",
    "    paths_of_leave_nodes = {}\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i] == True:\n",
    "            path = []\n",
    "            tmp = i\n",
    "            while( tmp >=0 and tmp in parents) :\n",
    "                tmp_parent = parents[tmp]\n",
    "                path.append(tmp_parent)\n",
    "                tmp = tmp_parent\n",
    "\n",
    "            paths_of_leave_nodes[i] = path\n",
    "    return [   set(  feature[n]  for n in paths_of_leave_nodes[i]  ) for i in leave_nodes]\n",
    "\n",
    "list_of_paths = [ get_path_from_tree(t) for t in c_passive.estimators_ ]\n",
    "import itertools\n",
    "all_paths = list(itertools.chain.from_iterable(list_of_paths))\n",
    "\n",
    "\n",
    "print(\"number of all leaves\", len(all_paths))\n",
    "print(\"average number of conditions\", sum ( [   len(i)    for i in all_paths] ) / len(all_paths)  )\n",
    "print(\"max number of conditions\", max ( [   len(i)    for i in all_paths] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T07:06:14.164583Z",
     "start_time": "2019-08-06T07:04:39.377058Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.7884231536926146\n",
      "Blackbox and our, acc 0.9132036847492323\n",
      "Blackbox and our,recall 0.7552581261950286\n",
      "Blackbox and our,precision 0.824634655532359\n",
      "number of support vectors (10866, 103)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "c_passive = SVC(gamma='scale',random_state=random_seed)\n",
    "\n",
    "# c_passive.fit(predicted_data_table.X, predicted_data_table.Y)\n",
    "# black_prediction = c_passive.predict(predicted_test_data_table.X)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "categorical_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_discrete]\n",
    "continuous_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_continuous]\n",
    "\n",
    "scikit_encoder = make_column_transformer( ( OneHotEncoder(categories='auto',sparse=False),categorical_features_idx),\n",
    "(StandardScaler(), continuous_features_idx),\n",
    "                    remainder = 'passthrough'\n",
    "                    )\n",
    "\n",
    "scikit_encoder.fit(data_table.X)\n",
    "\n",
    "c_passive.fit(scikit_encoder.transform(predicted_data_table.X), predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict( scikit_encoder.transform(predicted_test_data_table.X ))\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "print(\"number of support vectors\",c_passive.support_vectors_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T07:33:24.677894Z",
     "start_time": "2019-08-06T07:25:19.257572Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate 1.116636713151489\n",
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.7918987341772152\n",
      "Blackbox and our, acc 0.9158648925281474\n",
      "Blackbox and our,recall 0.7476099426386233\n",
      "Blackbox and our,precision 0.8417653390742734\n",
      "number of support vectors (22689, 103)\n"
     ]
    }
   ],
   "source": [
    "c_passive = SVC(gamma='scale',random_state=random_seed)\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "rate = ADS_active.synthetic_data_table.X.shape[0] / predicted_data_table.X.shape[0]\n",
    "print(\"sampling rate\",rate)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "categorical_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_discrete]\n",
    "continuous_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_continuous]\n",
    "\n",
    "scikit_encoder = make_column_transformer( ( OneHotEncoder(categories='auto',sparse=False),categorical_features_idx),\n",
    "(StandardScaler(), continuous_features_idx),\n",
    "                    remainder = 'passthrough'\n",
    "                    )\n",
    "\n",
    "scikit_encoder.fit(data_table.X)\n",
    "\n",
    "\n",
    "c_passive.fit(scikit_encoder.transform(new_predicted_data_table.X), new_predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict( scikit_encoder.transform(predicted_test_data_table.X ))\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "print(\"number of support vectors\",c_passive.support_vectors_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T07:48:33.070423Z",
     "start_time": "2019-08-06T07:46:39.183143Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.854079254079254\n",
      "Blackbox and our, acc 0.9359263050153531\n",
      "Blackbox and our,recall 0.875717017208413\n",
      "Blackbox and our,precision 0.8334849863512284\n",
      "number of parameter 28310\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "c_passive = MLPClassifier(solver='adam', alpha=1e-3,  hidden_layer_sizes=(100,100,50,50,10), random_state=random_seed,verbose=False)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "categorical_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_discrete]\n",
    "continuous_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_continuous]\n",
    "\n",
    "scikit_encoder = make_column_transformer( ( OneHotEncoder(categories='auto',sparse=False),categorical_features_idx),\n",
    "(StandardScaler(), continuous_features_idx),\n",
    "                    remainder = 'passthrough'\n",
    "                    )\n",
    "\n",
    "scikit_encoder.fit(data_table.X)\n",
    "\n",
    "c_passive.fit(scikit_encoder.transform(predicted_data_table.X), predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict( scikit_encoder.transform(predicted_test_data_table.X ))\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "print(\"number of parameter\", sum([  layer.shape[0]*layer.shape[1]  for layer in c_passive.coefs_ ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T07:54:42.078837Z",
     "start_time": "2019-08-06T07:48:33.073745Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate 1.116636713151489\n",
      "traning a blackbox to approximate a blackbox, with original dataset\n",
      "Blackbox and our, f1 score 0.8691099476439792\n",
      "Blackbox and our, acc 0.9437052200614124\n",
      "Blackbox and our,recall 0.872848948374761\n",
      "Blackbox and our,precision 0.8654028436018958\n",
      "number of parameter 28310\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "c_passive = MLPClassifier(solver='adam', alpha=1e-3,  hidden_layer_sizes=(100,100,50,50,10), random_state=random_seed,verbose=False)\n",
    "\n",
    "\n",
    "from utils import uniform_enlarge_dataset,estimated_enlarge_dataset\n",
    "rate = ADS_active.synthetic_data_table.X.shape[0] / predicted_data_table.X.shape[0]\n",
    "print(\"sampling rate\",rate)\n",
    "new_predicted_data_table = estimated_enlarge_dataset(predicted_data_table,black_box,sampling_rate=rate,random_seed=random_seed)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "categorical_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_discrete]\n",
    "continuous_features_idx = [i for i,a in enumerate(data_table.domain.attributes) if a.is_continuous]\n",
    "\n",
    "scikit_encoder = make_column_transformer( ( OneHotEncoder(categories='auto',sparse=False),categorical_features_idx),\n",
    "(StandardScaler(), continuous_features_idx),\n",
    "                    remainder = 'passthrough'\n",
    "                    )\n",
    "\n",
    "scikit_encoder.fit(data_table.X)\n",
    "\n",
    "\n",
    "c_passive.fit(scikit_encoder.transform(new_predicted_data_table.X), new_predicted_data_table.Y)\n",
    "black_prediction = c_passive.predict( scikit_encoder.transform(predicted_test_data_table.X ))\n",
    "\n",
    "\n",
    "import sklearn\n",
    "print(\"traning a blackbox to approximate a blackbox, with original dataset\")\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, black_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, black_prediction))\n",
    "print(\"number of parameter\", sum([  layer.shape[0]*layer.shape[1]  for layer in c_passive.coefs_ ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T22:25:45.344258Z",
     "start_time": "2019-08-10T22:25:45.220165Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### DTExtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:11.807330Z",
     "start_time": "2019-08-10T21:45:11.725069Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -2.  0. nan nan nan nan]\n",
      " [-2. nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([ [-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.3],[-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.3] ])\n",
    "\n",
    "tmp = np.rint(a,where=[[0,1,0,0,0,0,0], [1,0,0,0,0,0,0]] )\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T21:45:20.937971Z",
     "start_time": "2019-08-10T21:45:11.812691Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[age, workclass, education, marital-status, occupation, relationship, race, gender, capital-gain, capital-loss, hours-per-week, native-country | income]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dedb8eac2e8463f88c63879627a07ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "400\n",
      "400.0\n",
      "Blackbox and our, acc 0.8509723643807574\n",
      "Blackbox and our, f1 score 0.4965421853388658\n",
      "Blackbox and our,recall 0.34321223709369025\n",
      "Blackbox and our,precision 0.8975\n",
      "number of rules 45\n",
      "ave number of conditions 6.0\n",
      "max number of conditions 9\n",
      "used features 10\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from competition_methods_explanation.active_methods_top_down.dt import explain_tabular\n",
    "print(predicted_data_table.domain)\n",
    "explanations, tree = explain_tabular(\n",
    "    predicted_data_table,  black_box, target_class_idx=1, random_seed=42, active_instance_number = 0,termination_max=100)\n",
    "\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "# for e in explanations:\n",
    "#     print(rule_to_string(e,predicted_data_table.domain,target_class_idx=1))\n",
    "#     try:\n",
    "#         print(rule_to_string(e,disc_predicted_data_table.domain,target_class_idx=1))\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "\n",
    "our_prediction = ruleset_predict(explanations,predicted_test_data_table.X)\n",
    "tree_our_prediction = tree.predict(predicted_test_data_table.X)\n",
    "\n",
    "print(sum(our_prediction) )\n",
    "print(sum(tree_our_prediction))\n",
    "\n",
    "our_prediction = tree_our_prediction\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from competition_methods_explanation.active_methods_top_down.dt import compute_metrics_dt\n",
    "compute_metrics_dt(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T22:36:00.548531Z",
     "start_time": "2019-08-10T22:33:03.946815Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "start estimate the distribution\n",
      "using gaussian distribution\n",
      "finish estimate the distribution\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e06d08488ae49acb566790d5cf4c7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "266.0\n",
      "Blackbox and our, acc 0.8325486182190379\n",
      "Blackbox and our, f1 score 0.3765243902439025\n",
      "Blackbox and our,recall 0.2361376673040153\n",
      "Blackbox and our,precision 0.9285714285714286\n",
      "number of rules 49\n",
      "ave number of conditions 6.26530612244898\n",
      "max number of conditions 9\n",
      "used features 11\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from competition_methods_explanation.active_methods_top_down.dt import explain_tabular\n",
    "\n",
    "explanations, tree = explain_tabular(\n",
    "    predicted_data_table,  black_box, target_class_idx=1, random_seed=42, active_instance_number = 2000,termination_max=100)\n",
    "\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "# for e in explanations:\n",
    "#     print(rule_to_string(e,predicted_data_table.domain,target_class_idx=1))\n",
    "#     try:\n",
    "#         print(rule_to_string(e,disc_predicted_data_table.domain,target_class_idx=1))\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "our_prediction = ruleset_predict(explanations,predicted_test_data_table.X)\n",
    "tree_our_prediction = tree.predict(predicted_test_data_table.X)\n",
    "\n",
    "print( sum(our_prediction) )\n",
    "print(sum(tree_our_prediction))\n",
    "\n",
    "our_prediction = tree_our_prediction\n",
    "\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "from competition_methods_explanation.active_methods_top_down.dt import compute_metrics_dt\n",
    "compute_metrics_dt(explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor global version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T03:22:01.049924Z",
     "start_time": "2019-08-11T03:02:56.893985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea77de34c724c689b347517a2013f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d55c35e3f918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcompetition_methods_explanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_methods_bottom_up\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcn2anchor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcn2anchor_tabular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexplanations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcn2anchor_tabular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_data_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblack_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mrule_to_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mruleset_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/active_methods_bottom_up/cn2anchor.py\u001b[0m in \u001b[0;36mcn2anchor_tabular\u001b[0;34m(dataset, blackbox, target_class_idx, random_seed)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# fit the explainer to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcn2anchor_explainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblackbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mrule_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrule_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/active_methods_bottom_up/cn2anchor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, domain, target_class, W)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# rule_list.extend(self.find_rules(X, Y, W, target_class_idx,self.domain))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mrule_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# add the default rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# rule_list.append(self.generate_default_rule(X, Y, W, self.domain))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/active_methods_bottom_up/cn2anchor.py\u001b[0m in \u001b[0;36mfind_rules\u001b[0;34m(self, X, Y, W, target_class, domain)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# generate a new rule that has not been seen before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mnew_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;31m# the general requirements can be found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/active_methods_bottom_up/cn2anchor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, W, target_class, domain)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_anchor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mrule_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/active_methods_bottom_up/cn2anchor.py\u001b[0m in \u001b[0;36mfind_anchor\u001b[0;34m(self, X, Y, W, target_class, domain, idx, threshold)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfind_anchor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0manchor_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblackbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;31m# note that anchor exp is a different data structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# a converting is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/workspace/Descriptive-Induction-ML/competition_methods_explanation/active_methods_bottom_up/anchor/anchor_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0msample_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mdesired_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_anchor_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_anchor_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_names_to_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from competition_methods_explanation.active_methods_bottom_up.cn2anchor import cn2anchor_tabular\n",
    "explanations = cn2anchor_tabular(predicted_data_table, black_box, target_class_idx = 1, random_seed=42)\n",
    "\n",
    "from utils import  rule_to_string,ruleset_predict\n",
    "# for e in explanations:\n",
    "#     print(rule_to_string(e,predicted_data_table.domain,target_class_idx=1))\n",
    "#     try:\n",
    "#         print(rule_to_string(e,disc_predicted_data_table.domain,target_class_idx=1))\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "our_prediction = ruleset_predict(explanations,predicted_test_data_table.X)\n",
    "\n",
    "print( sum(our_prediction) )\n",
    "import sklearn\n",
    "print('Blackbox and our, acc', sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our, f1 score', sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,recall', sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction))\n",
    "print('Blackbox and our,precision', sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction))\n",
    "\n",
    "# from competition_methods_explanation.active_methods_top_down.dt import compute_metrics_dt\n",
    "from utils import compute_metrics\n",
    "compute_metrics(explanations,predicted_data_table.domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "tuing two parameter is relatively easy, we loop $\\lambda$ and $\\beta$ over a range of values and keep record of the resulted faithfulness and interpretability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.029590Z",
     "start_time": "2019-08-03T10:16:17.718Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from approach import explain_tabular\n",
    "from utils import ruleset_predict\n",
    "from copy import deepcopy\n",
    "\n",
    "lambda_candidates = [  0,0.0000001,0.000001,0.00001,0.00003,0.00005,0.00008,0.0001,0.0005,0.001,0.0013,0.0015,0.0018,0.002,0.0025,0.003,0.005,0.006,0.007,0.008,0.01,0.015,0.02,0.03,0.05,0.1,0.15,0.2,0.5 ]\n",
    "\n",
    "beta_candidates = [0,0.2,0.5,1.5,2,3,5,10]\n",
    "beta_candidates = [i * 0.00001 for i in beta_candidates]\n",
    "\n",
    "# lambda_candidates = [  0.01 ]\n",
    "# beta_candidates = [0]\n",
    "results={}\n",
    "for beta in beta_candidates:\n",
    "    results[beta] = []\n",
    "\n",
    "\n",
    "for beta in tqdm_notebook(beta_candidates): \n",
    "    lambda_parameter = lambda_candidates[0]\n",
    "    explanations,ADS = explain_tabular(predicted_data_table, black_box, target_class_idx=1, random_seed=42,beta=beta,lambda_parameter=lambda_parameter)\n",
    "    for lambda_parameter in  lambda_candidates:\n",
    "        explanations = ADS.output_the_best(lambda_parameter)\n",
    "        our_prediction = ruleset_predict(explanations,test_data_table.X)\n",
    "        f1_score = sklearn.metrics.f1_score(predicted_test_data_table.Y, our_prediction)\n",
    "        acc_score=sklearn.metrics.accuracy_score(predicted_test_data_table.Y, our_prediction)\n",
    "        rec_score = sklearn.metrics.recall_score(predicted_test_data_table.Y, our_prediction)\n",
    "        pre_score = sklearn.metrics.precision_score(predicted_test_data_table.Y, our_prediction)\n",
    "        num = len(explanations)\n",
    "        num_of_instance = ADS.synthetic_data_table.X.shape[0]\n",
    "        results[beta].append( (lambda_parameter,(num,f1_score,acc_score,rec_score,pre_score,num_of_instance,deepcopy(explanations) )  ) )\n",
    "        print(\"parameter: \",beta,lambda_parameter,\"metrics\",num,f1_score,acc_score,rec_score,pre_score,num_of_instance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.031113Z",
     "start_time": "2019-08-03T10:16:17.720Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# name = \"Greys\"\n",
    "# cmap = get_cmap(name)  # type: matplotlib.colors.ListedColormap\n",
    "# colors = cmap  # type: list\n",
    "\n",
    "# # plt.set_prop_cycle(color=colors)\n",
    "\n",
    "# color_map = get_cmap('viridis')\n",
    "color_map = get_cmap('binary')\n",
    "# color_map = get_cmap('winter')\n",
    "beta_candidates = [0,0.2,0.5,1.5,2,3,5,10]\n",
    "beta_candidates = [i * 0.00001 for i in beta_candidates]\n",
    "\n",
    "\n",
    "for count,b in enumerate(beta_candidates):\n",
    "#     if count in [3]: \n",
    "#         continue\n",
    "    plot_use_x = []\n",
    "    plot_use_y = []\n",
    "    for i in range(len(lambda_candidates)):\n",
    "        lambda_parameter,(num,f1_score,acc_score,rec_score,pre_score,num_of_instance,explanations) = results[b][i]\n",
    "        plot_use_x.append(num)\n",
    "#         plot_use_y.append(f1_score)\n",
    "        plot_use_y.append(acc_score)\n",
    "        \n",
    "    # for x,y in zip(plot_use_x,plot_use_y):\n",
    "    #     print(x,y)\n",
    "    tmp = [(x,y) for x,y in zip(plot_use_x,plot_use_y) ]\n",
    "#     tmp.append((0,0.5))\n",
    "#     tmp.append((100,1))\n",
    "    tmp = sorted(tmp,key=lambda x:x[0])\n",
    "    X =np.asarray([ t[0] for t in tmp]) .reshape(-1, 1)\n",
    "    y =np.asarray([ t[1] for t in tmp]) .reshape(-1, 1)\n",
    "#     clf = GaussianProcessRegressor()\n",
    "#     clf.fit(X, y) \n",
    "#     x_virtul = [ 0.1 * i for i in range(50)]\n",
    "#     x_for_predict = np.asarray(x_virtul) .reshape(-1, 1)\n",
    "#     plt.plot(x_virtul,clf.predict(x_for_predict).reshape(-1),color=color_map(  math.sqrt(b*1000)  )  )\n",
    "#     plt.plot(X,y  )\n",
    "    plt.plot(X,y,color=color_map(  math.sqrt(b*5000)  )  )\n",
    "\n",
    "#     format(12.456789, '.3e')\n",
    "plt.legend([str(b)for b in beta_candidates],loc=(1.04,0))\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# plt.legend([str(b) for b in beta_candidates], loc=5)\n",
    "# plt.xlim([3,10])\n",
    "# plt.ylim([0.8,1])\n",
    "plt.ylabel('f1 score')\n",
    "plt.xlabel('number of rules')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.032699Z",
     "start_time": "2019-08-03T10:16:17.723Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# name = \"Greys\"\n",
    "# cmap = get_cmap(name)  # type: matplotlib.colors.ListedColormap\n",
    "# colors = cmap  # type: list\n",
    "\n",
    "# # plt.set_prop_cycle(color=colors)\n",
    "\n",
    "# color_map = get_cmap('viridis')\n",
    "color_map = get_cmap('binary')\n",
    "\n",
    "\n",
    "\n",
    "# lambda_candidates = [  0,0.0000001,0.000001,0.00001,0.00003,0.00005,0.00008,0.0001,0.0005,0.001,0.0013,0.0015,0.0018,0.002,0.0025,0.003,0.005,0.006,0.007,0.008,0.01,0.015,0.02,0.03,0.05,0.1,0.15,0.2,0.5 ]\n",
    "\n",
    "\n",
    "# beta_candidates = [0,0.2,0.5,1,1.5,2,3,5,10]\n",
    "# beta_candidates = [i * 0.00001 for i in beta_candidates]\n",
    "\n",
    "for b in beta_candidates:\n",
    "    plot_use_x = []\n",
    "    plot_use_y = []\n",
    "    for i in range(len(lambda_candidates)):\n",
    "        lambda_parameter,(num,f1_score,acc_score,rec_score,pre_score,num_of_instance,explanations) = results[b][i]\n",
    "        plot_use_x.append(lambda_parameter)\n",
    "        plot_use_y.append(f1_score)\n",
    "    # for x,y in zip(plot_use_x,plot_use_y):\n",
    "    #     print(x,y)\n",
    "   \n",
    "    plt.plot(plot_use_x,plot_use_y,color=color_map(  math.sqrt(b*5000)  ))\n",
    "plt.legend([str(b) for b in beta_candidates], loc=(1.04,0))\n",
    "\n",
    "plt.ylabel('f1 score')\n",
    "plt.xlabel('lambda')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.034224Z",
     "start_time": "2019-08-03T10:16:17.725Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_map = get_cmap('binary')\n",
    "for b in beta_candidates:\n",
    "    plot_use_x = []\n",
    "    plot_use_y = []\n",
    "    for i in range(len(lambda_candidates)):\n",
    "        lambda_parameter,(num,f1_score,acc_score,rec_score,pre_score,num_of_instance,explanations) = results[b][i]\n",
    "        plot_use_x.append(lambda_parameter)\n",
    "        plot_use_y.append(num)\n",
    "    # for x,y in zip(plot_use_x,plot_use_y):\n",
    "    #     print(x,y)\n",
    "    plt.plot(plot_use_x,plot_use_y,color=color_map(  math.sqrt(b*1000)  ))\n",
    "plt.legend([str(b) for b in beta_candidates], loc=(1.04,0))\n",
    "\n",
    "plt.ylabel('num of rules')\n",
    "plt.xlabel('lambda')\n",
    "plt.xlim([0,0.01])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.036011Z",
     "start_time": "2019-08-03T10:16:17.728Z"
    }
   },
   "outputs": [],
   "source": [
    "score_list=[]\n",
    "for i,l in enumerate(lambda_candidates):\n",
    "    for b in beta_candidates:\n",
    "\n",
    "        lambda_parameter,(num,f1_score,acc_score,rec_score,pre_score,num_of_instance,explanations) = results[b][i]\n",
    "        score_list.append(  (l,b,num,f1_score,acc_score,rec_score,pre_score) )\n",
    "\n",
    "score_list = sorted(score_list,reverse=True,key=lambda x:x[4])\n",
    "print(score_list[0])\n",
    "l,b,num,f1_score,acc_score,rec_score,pre_score = score_list[0]\n",
    "print(\"the best lambda: \",l)\n",
    "print(\"the best beta:\",b)\n",
    "print(\"f1:\",f1_score,\" acc: \",acc_score,\" recall: \",rec_score,\" precision: \",pre_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T04:51:50.665484Z",
     "start_time": "2019-07-18T04:51:50.578505Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.038786Z",
     "start_time": "2019-08-03T10:16:17.732Z"
    }
   },
   "outputs": [],
   "source": [
    "for b in results:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T11:58:19.041710Z",
     "start_time": "2019-08-03T10:16:17.745Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint as pr\n",
    "pr(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.0.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
